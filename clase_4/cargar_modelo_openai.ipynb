{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWRLbJinfIm-",
        "outputId": "3af4af0f-e72a-4586-c6ae-834a16896cae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (2.8.1)\n",
            "Requirement already satisfied: python-dotenv-vault in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (0.7.0)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from openai) (2.12.5)\n",
            "Requirement already satisfied: sniffio in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from python-dotenv-vault) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=41.0.0 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from python-dotenv-vault) (46.0.3)\n",
            "Collecting regex>=2022.1.18 (from tiktoken)\n",
            "  Downloading regex-2025.11.3-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
            "Collecting requests>=2.26.0 (from tiktoken)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from cryptography>=41.0.0->python-dotenv-vault) (2.0.0)\n",
            "Requirement already satisfied: pycparser in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=41.0.0->python-dotenv-vault) (2.23)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken)\n",
            "  Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\jdbm_\\onedrive\\documentos\\platzi\\curso de desarrollo de chatbots con openai\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl (879 kB)\n",
            "   ---------------------------------------- 0.0/879.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 879.1/879.1 kB 15.9 MB/s  0:00:00\n",
            "Downloading regex-2025.11.3-cp313-cp313-win_amd64.whl (277 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Installing collected packages: urllib3, regex, charset_normalizer, requests, tiktoken\n",
            "\n",
            "   ---------------------------------------- 0/5 [urllib3]\n",
            "   ---------------------------------------- 0/5 [urllib3]\n",
            "   ---------------------------------------- 0/5 [urllib3]\n",
            "   ---------------------------------------- 0/5 [urllib3]\n",
            "   ---------------------------------------- 0/5 [urllib3]\n",
            "   ---------------------------------------- 0/5 [urllib3]\n",
            "   ---------------------------------------- 0/5 [urllib3]\n",
            "   ---------------------------------------- 0/5 [urllib3]\n",
            "   ---------------------------------------- 0/5 [urllib3]\n",
            "   ---------------------------------------- 0/5 [urllib3]\n",
            "   -------- ------------------------------- 1/5 [regex]\n",
            "   -------- ------------------------------- 1/5 [regex]\n",
            "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
            "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
            "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
            "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
            "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
            "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
            "   ------------------------ --------------- 3/5 [requests]\n",
            "   ------------------------ --------------- 3/5 [requests]\n",
            "   ------------------------ --------------- 3/5 [requests]\n",
            "   ------------------------ --------------- 3/5 [requests]\n",
            "   ------------------------ --------------- 3/5 [requests]\n",
            "   ------------------------ --------------- 3/5 [requests]\n",
            "   -------------------------------- ------- 4/5 [tiktoken]\n",
            "   -------------------------------- ------- 4/5 [tiktoken]\n",
            "   -------------------------------- ------- 4/5 [tiktoken]\n",
            "   ---------------------------------------- 5/5 [tiktoken]\n",
            "\n",
            "Successfully installed charset_normalizer-3.4.4 regex-2025.11.3 requests-2.32.5 tiktoken-0.12.0 urllib3-2.5.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai python-dotenv-vault tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JMiHUAbSgmsS"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv_vault import load_dotenv\n",
        "import tiktoken\n",
        "import os\n",
        "from IPython.display import display,Markdown\n",
        "# Cargar variables de entorno desde el archivo .env\n",
        "load_dotenv()\n",
        "\n",
        "# Obtener la API Key desde las variables de entorno\n",
        "OPENAI_KEY = os.getenv('OPENAI_KEY')\n",
        "\n",
        "# Si estás en Google Colab, puedes usar esta alternativa:\n",
        "# from google.colab import userdata\n",
        "# OPENAI_KEY = userdata.get('OPENAI_KEY')\n",
        "\n",
        "openai = OpenAI(api_key=OPENAI_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNKHA3Phgws3",
        "outputId": "7201bdec-ae38-43af-891d-ee86ed45384c"
      },
      "outputs": [],
      "source": [
        "response = openai.chat.completions.create(\n",
        "    model = 'gpt-4.1-nano',\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\" :\"Eres un asistente que da informacion a dudas\"},\n",
        "        {\"role\": \"user\", \"content\" :\"¿Quién descubrió América?\"}\n",
        "    ],\n",
        "    max_tokens = 50,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9253KN3KNJKf",
        "outputId": "e2264882-20ea-4d55-bd6a-0b2ebf2bfcb2"
      },
      "outputs": [],
      "source": [
        "response = openai.chat.completions.create(\n",
        "    model = 'gpt-4.1-nano',\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\" :\"Eres un asistente que da informacion a dudas\"},\n",
        "        {\"role\": \"user\", \"content\" :\"¿Quién descubrió América?\"}\n",
        "    ],\n",
        "    max_tokens = 50,\n",
        "    temperature = 1,\n",
        "    top_p = 1,\n",
        "    n = 2\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(response.choices[1].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La IA, o inteligencia artificial, es una rama de la informática que se enfoca en crear sistemas o programas capaces de realizar tareas que normalmente requieren de la inteligencia humana. Estas tareas incluyen el aprendizaje, la resolución de problemas, la comprensión del lenguaje natural, el reconocimiento de imágenes, la toma de decisiones y más. La IA puede ser clasificada en diferentes tipos, como la IA débil (diseñada para tareas específicas) y la IA fuerte (que tendría capacidades cognitivas similares a las\n"
          ]
        }
      ],
      "source": [
        "response = openai.chat.completions.create(\n",
        "    model = 'gpt-4.1-nano',\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\" :\"Eres un asistente que da informacion a dudas\"},\n",
        "        {\"role\": \"user\", \"content\" :\"¿Qué es IA?\"}\n",
        "    ],\n",
        "    max_tokens = 100,\n",
        "    temperature = 0.3,\n",
        "    top_p = 1,\n",
        "    n = 1\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "La IA, o inteligencia artificial, se refiere a la capacidad de las máquinas y programas informáticos para realizar tareas que normalmente requieren inteligencia humana. Esto incluye habilidades como aprender, razonar, resolver problemas, entender el lenguaje natural, reconocer patrones y tomar decisiones. La IA se aplica en diferentes áreas como asistentes virtuales, diagnósticos médicos, vehículos autónomos, reconocimiento de voz y muchas otras tecnologías que buscan imitar o potenciar las capacidades humanas."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "encoding = tiktoken.encoding_for_model(\"gpt-4.1-nano\")\n",
        "\n",
        "response = openai.chat.completions.create(\n",
        "    model = 'gpt-4.1-nano',\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\" :\"Eres un asistente que da informacion a dudas\"},\n",
        "        {\"role\": \"user\", \"content\" :\"¿Qué es IA?\"}\n",
        "    ],\n",
        "    max_tokens = 100,\n",
        "    temperature = 1,\n",
        "    top_p = 1,\n",
        "    n = 1,\n",
        "    stream=True,\n",
        ")\n",
        "all_text = \"\"\n",
        "markdown_display = display(Markdown(\"\"), display_id=True)\n",
        "\n",
        "for chunk in response:\n",
        "    choices = chunk.choices\n",
        "    if choices:\n",
        "        delta = choices[0].delta\n",
        "        if delta.content:\n",
        "            all_text += delta.content\n",
        "            # Actualizar el Markdown en tiempo real\n",
        "            markdown_display.update(Markdown(all_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La IA, o inteligencia artificial, se refiere a la capacidad de las máquinas y programas informáticos para realizar tareas que normalmente requieren inteligencia humana. Esto incluye habilidades como aprender, razonar, resolver problemas, entender el lenguaje natural, reconocer patrones y tomar decisiones. La IA se aplica en diferentes áreas como asistentes virtuales, diagnósticos médicos, vehículos autónomos, reconocimiento de voz y muchas otras tecnologías que buscan imitar o potenciar las capacidades humanas.\n",
            "Cantidad de tokens: 89\n"
          ]
        }
      ],
      "source": [
        "encoding = tiktoken.encoding_for_model(\"gpt-4.1-nano\")\n",
        "print(all_text)\n",
        "tokens = encoding.encode(all_text)\n",
        "cantidad_tokens = len(tokens)\n",
        "print(f\"Cantidad de tokens: {cantidad_tokens}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
